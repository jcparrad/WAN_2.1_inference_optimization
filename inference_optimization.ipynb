{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ffe97ed-7069-4b0b-ac40-e159d57d6a6d",
   "metadata": {},
   "source": [
    "# Experimentation on WAn VACE. Inference Otimization\n",
    "\n",
    "there are several experiments, that incremets the complexity\n",
    "1. One process that uses only 4 GPUS H100. Only one task of video generatio. Total time 262.15 sec\n",
    "2. Two processes. Each process uses 4 GPUS H100 (so the 8XH100 GPUS are used). Each process with only one task. Total time 263.31 sec\n",
    "3. Two processes. Each process uses 4 GPUS H100 (so the 8XH100 GPUS are used). Each process with 10 tasks. Total time 1850 sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78931c3-04d8-4085-96a0-605ecd4e21eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "480d3b5d",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "One process that uses only 4 GPUS H100. Only one task of video generatio. Total time 262.15 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f076034-d938-4c10-b80b-a45e54b23d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0724 17:08:26.385000 140517213615936 torch/distributed/run.py:779] \n",
      "W0724 17:08:26.385000 140517213615936 torch/distributed/run.py:779] *****************************************\n",
      "W0724 17:08:26.385000 140517213615936 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0724 17:08:26.385000 140517213615936 torch/distributed/run.py:779] *****************************************\n",
      "[2025-07-24 17:08:32,821] INFO: offload_model is not specified, set to False.\n",
      "DEBUG 07-24 17:08:33 [parallel_state.py:207] world_size=4 rank=0 local_rank=-1 distributed_init_method=env:// backend=nccl\n",
      "DEBUG 07-24 17:08:33 [parallel_state.py:207] world_size=4 rank=1 local_rank=-1 distributed_init_method=env:// backend=nccl\n",
      "DEBUG 07-24 17:08:33 [parallel_state.py:207] world_size=4 rank=2 local_rank=-1 distributed_init_method=env:// backend=nccl\n",
      "DEBUG 07-24 17:08:33 [parallel_state.py:207] world_size=4 rank=3 local_rank=-1 distributed_init_method=env:// backend=nccl\n",
      "[2025-07-24 17:08:33,907] INFO: Generation job args: Namespace(task='vace-14B', size='832*480', frame_num=81, ckpt_dir='/workspace/Wan2.1-VACE-14B', offload_model=False, ulysses_size=4, ring_size=1, t5_fsdp=True, t5_cpu=False, dit_fsdp=True, save_file='/workspace/experiments/inference_optimzation/output/output_licuadora_v1_832_480.mp4', src_video=None, src_mask=None, src_ref_images='/workspace/experiments/experiments_inpaiting_outpainting_mask/data/licuadora1.png', prompt='A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.', use_prompt_extend=False, prompt_extend_method='local_qwen', prompt_extend_model=None, prompt_extend_target_lang='zh', base_seed=7681909654112168816, image=None, first_frame=None, last_frame=None, sample_solver='unipc', sample_steps=50, sample_shift=16, sample_guide_scale=5.0)\n",
      "[2025-07-24 17:08:33,907] INFO: Generation model config: {'__name__': 'Config: Wan T2V 14B', 't5_model': 'umt5_xxl', 't5_dtype': torch.bfloat16, 'text_len': 512, 'param_dtype': torch.bfloat16, 'num_train_timesteps': 1000, 'sample_fps': 16, 'sample_neg_prompt': '色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走', 't5_checkpoint': 'models_t5_umt5-xxl-enc-bf16.pth', 't5_tokenizer': 'google/umt5-xxl', 'vae_checkpoint': 'Wan2.1_VAE.pth', 'vae_stride': (4, 8, 8), 'patch_size': (1, 2, 2), 'dim': 5120, 'ffn_dim': 13824, 'freq_dim': 256, 'num_heads': 40, 'num_layers': 40, 'window_size': (-1, -1), 'qk_norm': True, 'cross_attn_norm': True, 'eps': 1e-06}\n",
      "[2025-07-24 17:08:35,789] INFO: Input prompt: A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\n",
      "[2025-07-24 17:08:35,789] INFO: Creating VACE pipeline.\n",
      "[2025-07-24 17:09:17,470] INFO: loading /workspace/Wan2.1-VACE-14B/models_t5_umt5-xxl-enc-bf16.pth\n",
      "Loading checkpoint shards:   0%|                          | 0/7 [00:00<?, ?it/s][2025-07-24 17:09:25,157] INFO: loading /workspace/Wan2.1-VACE-14B/Wan2.1_VAE.pth\n",
      "Loading checkpoint shards:   0%|                          | 0/7 [00:00<?, ?it/s][2025-07-24 17:09:25,388] INFO: Creating VaceWanModel from /workspace/Wan2.1-VACE-14B\n",
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:02<00:00,  2.41it/s]\n",
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:02<00:00,  2.47it/s]\n",
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:02<00:00,  2.48it/s]\n",
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:02<00:00,  2.34it/s]\n",
      "[2025-07-24 17:09:45,589] INFO: Generating video...\n",
      "100%|███████████████████████████████████████████| 50/50 [02:52<00:00,  3.44s/it]\n",
      "100%|███████████████████████████████████████████| 50/50 [02:52<00:00,  3.44s/it]\n",
      "100%|███████████████████████████████████████████| 50/50 [02:52<00:00,  3.44s/it]\n",
      "100%|███████████████████████████████████████████| 50/50 [02:52<00:00,  3.44s/it]\n",
      "[2025-07-24 17:12:44,170] INFO: Saving generated video to /workspace/experiments/inference_optimzation/output/output_licuadora_v1_832_480.mp4\n",
      "[2025-07-24 17:12:44,688] INFO: Finished.\n",
      "[rank0]:[W724 17:12:45.210882742 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
      "⏱️ Tiempo de ejecución: 262.15 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "!torchrun --nproc_per_node=4 \\\n",
    "  /workspace/Wan2.1/generate.py \\\n",
    "  --task vace-14B \\\n",
    "  --size 832*480 \\\n",
    "  --ckpt_dir /workspace/Wan2.1-VACE-14B \\\n",
    "  --dit_fsdp \\\n",
    "  --t5_fsdp \\\n",
    "  --ulysses_size 4 \\\n",
    "  --src_ref_images /workspace/experiments/experiments_inpaiting_outpainting_mask/data/licuadora1.png \\\n",
    "  --prompt \"A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\" \\\n",
    "  --save_file /workspace/experiments/inference_optimzation/output/output_licuadora_v1_832_480.mp4\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"⏱️ Tiempo de ejecución: {end_time - start_time:.2f} segundos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf7ab21-9b65-4ff3-ad43-bbcbd3be2fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "958589ab",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "\n",
    "Two processes. Each process uses 4 GPUS H100 (so the 8XH100 GPUS are used). Each process with only one task. Total time 263.31 sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b0b6658-f731-44d5-8ea7-db2adb18743a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏱️ Tiempo total de ejecución: 263.31 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIGURACIÓN GENERAL ===\n",
    "output_dir = Path(\"/workspace/experiments/inference_optimzation/output\")\n",
    "log_dir = output_dir / \"logs\"\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# === COMANDO 1 - GPUs 0-3, puerto 29501 ===\n",
    "log1_path = log_dir / \"v1.log\"\n",
    "log1 = open(log1_path, \"w\")\n",
    "\n",
    "proc1 = subprocess.Popen([\n",
    "    \"torchrun\", \"--nproc_per_node=4\", \"--master_port=29501\",\n",
    "    \"/workspace/Wan2.1/generate.py\",\n",
    "    \"--task\", \"vace-14B\",\n",
    "    \"--size\", \"832*480\",\n",
    "    \"--ckpt_dir\", \"/workspace/Wan2.1-VACE-14B\",\n",
    "    \"--dit_fsdp\",\n",
    "    \"--t5_fsdp\",\n",
    "    \"--ulysses_size\", \"4\",\n",
    "    \"--src_ref_images\", str(output_dir / \"licuadora1.png\"),\n",
    "    \"--prompt\", \"A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\",\n",
    "    \"--save_file\", str(output_dir / \"output_licuadora_v1_832_480.mp4\")\n",
    "], env={**os.environ, \"CUDA_VISIBLE_DEVICES\": \"0,1,2,3\"}, stdout=log1, stderr=log1)\n",
    "\n",
    "# === COMANDO 2 - GPUs 4-7, puerto 29502 ===\n",
    "log2_path = log_dir / \"v2.log\"\n",
    "log2 = open(log2_path, \"w\")\n",
    "\n",
    "proc2 = subprocess.Popen([\n",
    "    \"torchrun\", \"--nproc_per_node=4\", \"--master_port=29502\",\n",
    "    \"/workspace/Wan2.1/generate.py\",\n",
    "    \"--task\", \"vace-14B\",\n",
    "    \"--size\", \"832*480\",\n",
    "    \"--ckpt_dir\", \"/workspace/Wan2.1-VACE-14B\",\n",
    "    \"--dit_fsdp\",\n",
    "    \"--t5_fsdp\",\n",
    "    \"--ulysses_size\", \"4\",\n",
    "    \"--src_ref_images\", str(output_dir / \"licuadora1.png\"),\n",
    "    \"--prompt\", \"A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\",\n",
    "    \"--save_file\", str(output_dir / \"output_licuadora_v2_832_480.mp4\")\n",
    "], env={**os.environ, \"CUDA_VISIBLE_DEVICES\": \"4,5,6,7\"}, stdout=log2, stderr=log2)\n",
    "\n",
    "# === ESPERAR A QUE AMBOS TERMINEN ===\n",
    "proc1.wait()\n",
    "proc2.wait()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"⏱️ Tiempo total de ejecución: {end_time - start_time:.2f} segundos\")\n",
    "\n",
    "# === CERRAR LOGS ===\n",
    "log1.close()\n",
    "log2.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09ec12c-1a80-4545-ad16-2cf6b22824fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9294e28a-1e4e-4d73-95ab-0355334751af",
   "metadata": {},
   "source": [
    "# Experiment 3\n",
    "Two processes. Each process uses 4 GPUS H100 (so the 8XH100 GPUS are used). Each process with 10 tasks. Total time 1850 sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "954b8c8b-7091-401c-b190-f7b4d93fc014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0725 15:40:25.042000 140105320523584 torch/distributed/run.py:779] \n",
      "W0725 15:40:25.042000 140105320523584 torch/distributed/run.py:779] *****************************************\n",
      "W0725 15:40:25.042000 140105320523584 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0725 15:40:25.042000 140105320523584 torch/distributed/run.py:779] *****************************************\n",
      "W0725 15:40:25.042000 139796101019456 torch/distributed/run.py:779] \n",
      "W0725 15:40:25.042000 139796101019456 torch/distributed/run.py:779] *****************************************\n",
      "W0725 15:40:25.042000 139796101019456 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0725 15:40:25.042000 139796101019456 torch/distributed/run.py:779] *****************************************\n",
      "/workspace/Wan2.1/wan/modules/model.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "/workspace/Wan2.1/wan/modules/model.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "/workspace/Wan2.1/wan/modules/model.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "/workspace/Wan2.1/wan/modules/model.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "/workspace/Wan2.1/wan/modules/model.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "/workspace/Wan2.1/wan/modules/model.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "/workspace/Wan2.1/wan/modules/model.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "/workspace/Wan2.1/wan/modules/model.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "/workspace/Wan2.1/wan/modules/model.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "/workspace/Wan2.1/wan/modules/model.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "/workspace/Wan2.1/wan/modules/model.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "/workspace/Wan2.1/wan/modules/model.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "/workspace/Wan2.1/wan/modules/model.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "/workspace/Wan2.1/wan/modules/model.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "/workspace/Wan2.1/wan/modules/model.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "/workspace/Wan2.1/wan/modules/model.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "DEBUG 07-25 15:40:33 [parallel_state.py:215] world_size=4 rank=0 local_rank=-1 distributed_init_method=env:// backend=nccl\n",
      "DEBUG 07-25 15:40:33 [parallel_state.py:215] world_size=4 rank=0 local_rank=-1 distributed_init_method=env:// backend=nccl\n",
      "DEBUG 07-25 15:40:33 [parallel_state.py:215] world_size=4 rank=1 local_rank=-1 distributed_init_method=env:// backend=nccl\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "DEBUG 07-25 15:40:33 [parallel_state.py:215] world_size=4 rank=2 local_rank=-1 distributed_init_method=env:// backend=nccl\n",
      "DEBUG 07-25 15:40:33 [parallel_state.py:215] world_size=4 rank=3 local_rank=-1 distributed_init_method=env:// backend=nccl\n",
      "DEBUG 07-25 15:40:33 [parallel_state.py:215] world_size=4 rank=3 local_rank=-1 distributed_init_method=env:// backend=nccl\n",
      "DEBUG 07-25 15:40:33 [parallel_state.py:215] world_size=4 rank=2 local_rank=-1 distributed_init_method=env:// backend=nccl\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "DEBUG 07-25 15:40:33 [parallel_state.py:215] world_size=4 rank=1 local_rank=-1 distributed_init_method=env:// backend=nccl\n",
      "[2025-07-25 15:41:15,302] INFO: loading /workspace/Wan2.1-VACE-14B/models_t5_umt5-xxl-enc-bf16.pth\n",
      "/workspace/Wan2.1/wan/modules/t5.py:496: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
      "/workspace/Wan2.1/wan/modules/t5.py:496: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
      "/workspace/Wan2.1/wan/modules/t5.py:496: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
      "/workspace/Wan2.1/wan/modules/t5.py:496: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
      "/workspace/Wan2.1/wan/modules/t5.py:496: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
      "/workspace/Wan2.1/wan/modules/t5.py:496: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
      "/workspace/Wan2.1/wan/modules/t5.py:496: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
      "[2025-07-25 15:41:16,676] INFO: loading /workspace/Wan2.1-VACE-14B/models_t5_umt5-xxl-enc-bf16.pth\n",
      "/workspace/Wan2.1/wan/modules/t5.py:496: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
      "[2025-07-25 15:41:22,721] INFO: loading /workspace/Wan2.1-VACE-14B/Wan2.1_VAE.pth\n",
      "/workspace/Wan2.1/wan/modules/vae.py:614: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(pretrained_path, map_location=device), assign=True)\n",
      "[2025-07-25 15:41:22,937] INFO: Creating VaceWanModel from /workspace/Wan2.1-VACE-14B\n",
      "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]/workspace/Wan2.1/wan/modules/vae.py:614: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(pretrained_path, map_location=device), assign=True)\n",
      "/workspace/Wan2.1/wan/modules/vae.py:614: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(pretrained_path, map_location=device), assign=True)\n",
      "/workspace/Wan2.1/wan/modules/vae.py:614: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(pretrained_path, map_location=device), assign=True)\n",
      "/workspace/Wan2.1/wan/modules/vae.py:614: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(pretrained_path, map_location=device), assign=True)\n",
      "/workspace/Wan2.1/wan/modules/vae.py:614: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(pretrained_path, map_location=device), assign=True)\n",
      "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]/workspace/Wan2.1/wan/modules/vae.py:614: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(pretrained_path, map_location=device), assign=True)\n",
      "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s][2025-07-25 15:41:24,704] INFO: loading /workspace/Wan2.1-VACE-14B/Wan2.1_VAE.pth\n",
      "/workspace/Wan2.1/wan/modules/vae.py:614: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(pretrained_path, map_location=device), assign=True)\n",
      "[2025-07-25 15:41:24,958] INFO: Creating VaceWanModel from /workspace/Wan2.1-VACE-14B\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:02<00:00,  2.40it/s]\n",
      "/workspace/Wan2.1/wan/distributed/xdit_context_parallel.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:02<00:00,  2.41it/s]\n",
      "/workspace/Wan2.1/wan/distributed/xdit_context_parallel.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:02<00:00,  2.43it/s]\n",
      "/workspace/Wan2.1/wan/distributed/xdit_context_parallel.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:02<00:00,  2.43it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:02<00:00,  2.35it/s]\n",
      "/workspace/Wan2.1/wan/distributed/xdit_context_parallel.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "/workspace/Wan2.1/wan/distributed/xdit_context_parallel.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:02<00:00,  2.40it/s]\n",
      "/workspace/Wan2.1/wan/distributed/xdit_context_parallel.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:02<00:00,  2.42it/s]\n",
      "/workspace/Wan2.1/wan/distributed/xdit_context_parallel.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:02<00:00,  2.41it/s]\n",
      "/workspace/Wan2.1/wan/distributed/xdit_context_parallel.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "[2025-07-25 15:41:44,172] INFO: [1/10] Generando video para prompt: A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\n",
      "/workspace/Wan2.1/wan/modules/vae.py:651: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=self.dtype):\n",
      "/workspace/Wan2.1/wan/modules/vae.py:651: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=self.dtype):\n",
      "/workspace/Wan2.1/wan/modules/vae.py:651: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=self.dtype):\n",
      "/workspace/Wan2.1/wan/modules/vae.py:651: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=self.dtype):\n",
      "[2025-07-25 15:41:45,946] INFO: [1/10] Generando video para prompt: A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\n",
      "/workspace/Wan2.1/wan/modules/vae.py:651: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=self.dtype):\n",
      "/workspace/Wan2.1/wan/modules/vae.py:651: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=self.dtype):\n",
      "/workspace/Wan2.1/wan/modules/vae.py:651: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=self.dtype):\n",
      "/workspace/Wan2.1/wan/modules/vae.py:651: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=self.dtype):\n",
      "/workspace/Wan2.1/wan/vace.py:400: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=self.param_dtype), torch.no_grad(), no_sync():\n",
      "/workspace/Wan2.1/wan/vace.py:400: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=self.param_dtype), torch.no_grad(), no_sync():\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]/workspace/Wan2.1/wan/vace.py:400: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=self.param_dtype), torch.no_grad(), no_sync():\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]/workspace/Wan2.1/wan/vace.py:400: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=self.param_dtype), torch.no_grad(), no_sync():\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]/workspace/Wan2.1/wan/distributed/xdit_context_parallel.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/distributed/xdit_context_parallel.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/distributed/xdit_context_parallel.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/distributed/xdit_context_parallel.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:297: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:297: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:297: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:297: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/vace.py:400: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=self.param_dtype), torch.no_grad(), no_sync():\n",
      "/workspace/Wan2.1/wan/vace.py:400: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=self.param_dtype), torch.no_grad(), no_sync():\n",
      "/workspace/Wan2.1/wan/vace.py:400: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=self.param_dtype), torch.no_grad(), no_sync():\n",
      "/workspace/Wan2.1/wan/vace.py:400: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=self.param_dtype), torch.no_grad(), no_sync():\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]/workspace/Wan2.1/wan/distributed/xdit_context_parallel.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/distributed/xdit_context_parallel.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/distributed/xdit_context_parallel.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/distributed/xdit_context_parallel.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:297: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:297: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:297: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:297: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:312: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:312: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:312: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:312: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:344: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:344: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:344: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:344: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:312: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:312: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:312: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:312: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:344: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:344: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:344: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "/workspace/Wan2.1/wan/modules/model.py:344: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=torch.float32):\n",
      "100%|██████████| 50/50 [02:52<00:00,  3.45s/it]\n",
      "100%|██████████| 50/50 [02:52<00:00,  3.45s/it]\n",
      "100%|██████████| 50/50 [02:52<00:00,  3.45s/it]\n",
      "\n",
      "/workspace/Wan2.1/wan/modules/vae.py:658: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=self.dtype):\n",
      "100%|██████████| 50/50 [02:53<00:00,  3.47s/it]\n",
      "\n",
      "100%|██████████| 50/50 [02:53<00:00,  3.47s/it]\n",
      "100%|██████████| 50/50 [02:53<00:00,  3.47s/it]\n",
      "/workspace/Wan2.1/wan/modules/vae.py:658: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=self.dtype):\n",
      "[2025-07-25 15:44:43,283] INFO: Guardando video en /workspace/inference_optimization/output/output_licuadora_832_480_v1_1.mp4\n",
      "[2025-07-25 15:44:43,756] INFO: [2/10] Generando video para prompt: A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\n",
      "[2025-07-25 15:44:45,832] INFO: Guardando video en /workspace/inference_optimization/output/output_licuadora_832_480_v2_1.mp4\n",
      "[2025-07-25 15:44:46,327] INFO: [2/10] Generando video para prompt: A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      " 98%|█████████▊| 49/50 [02:46<00:03,  3.39s/it][2025-07-25 15:47:38,283] INFO: Guardando video en /workspace/inference_optimization/output/output_licuadora_832_480_v1_2.mp4\n",
      "[2025-07-25 15:47:38,749] INFO: [3/10] Generando video para prompt: A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "[2025-07-25 15:47:41,946] INFO: Guardando video en /workspace/inference_optimization/output/output_licuadora_832_480_v2_2.mp4\n",
      "  0%|          | 0/50 [00:00<?, ?it/s][2025-07-25 15:47:42,428] INFO: [3/10] Generando video para prompt: A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "\n",
      " 98%|█████████▊| 49/50 [02:46<00:03,  3.39s/it][2025-07-25 15:50:33,359] INFO: Guardando video en /workspace/inference_optimization/output/output_licuadora_832_480_v1_3.mp4\n",
      "[2025-07-25 15:50:33,824] INFO: [4/10] Generando video para prompt: A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.40s/it]\n",
      "\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.40s/it]\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s][2025-07-25 15:50:38,304] INFO: Guardando video en /workspace/inference_optimization/output/output_licuadora_832_480_v2_3.mp4\n",
      "[2025-07-25 15:50:38,791] INFO: [4/10] Generando video para prompt: A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "[2025-07-25 15:53:28,345] INFO: Guardando video en /workspace/inference_optimization/output/output_licuadora_832_480_v1_4.mp4\n",
      " 98%|█████████▊| 49/50 [02:46<00:03,  3.39s/it][2025-07-25 15:53:28,815] INFO: [5/10] Generando video para prompt: A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.40s/it]\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.40s/it]\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.40s/it]\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.40s/it]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s][2025-07-25 15:53:34,641] INFO: Guardando video en /workspace/inference_optimization/output/output_licuadora_832_480_v2_4.mp4\n",
      "[2025-07-25 15:53:35,134] INFO: [5/10] Generando video para prompt: A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "\n",
      " 96%|█████████▌| 48/50 [02:42<00:06,  3.38s/it][2025-07-25 15:56:23,321] INFO: Guardando video en /workspace/inference_optimization/output/output_licuadora_832_480_v1_5.mp4\n",
      "[2025-07-25 15:56:23,787] INFO: [6/10] Generando video para prompt: A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "  2%|▏         | 1/50 [00:03<02:45,  3.37s/it][2025-07-25 15:56:30,616] INFO: Guardando video en /workspace/inference_optimization/output/output_licuadora_832_480_v2_5.mp4\n",
      "[2025-07-25 15:56:31,107] INFO: [6/10] Generando video para prompt: A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      " 96%|█████████▌| 48/50 [02:42<00:06,  3.38s/it][2025-07-25 15:59:18,300] INFO: Guardando video en /workspace/inference_optimization/output/output_licuadora_832_480_v1_6.mp4\n",
      "[2025-07-25 15:59:18,803] INFO: [7/10] Generando video para prompt: A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "  2%|▏         | 1/50 [00:03<02:44,  3.36s/it][2025-07-25 15:59:26,567] INFO: Guardando video en /workspace/inference_optimization/output/output_licuadora_832_480_v2_6.mp4\n",
      "[2025-07-25 15:59:27,048] INFO: [7/10] Generando video para prompt: A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      " 96%|█████████▌| 48/50 [02:42<00:06,  3.39s/it][2025-07-25 16:02:13,367] INFO: Guardando video en /workspace/inference_optimization/output/output_licuadora_832_480_v1_7.mp4\n",
      "[2025-07-25 16:02:13,840] INFO: [8/10] Generando video para prompt: A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "  2%|▏         | 1/50 [00:03<02:44,  3.37s/it][2025-07-25 16:02:22,529] INFO: Guardando video en /workspace/inference_optimization/output/output_licuadora_832_480_v2_7.mp4\n",
      "[2025-07-25 16:02:23,022] INFO: [8/10] Generando video para prompt: A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "[2025-07-25 16:05:08,473] INFO: Guardando video en /workspace/inference_optimization/output/output_licuadora_832_480_v1_8.mp4\n",
      "[2025-07-25 16:05:08,948] INFO: [9/10] Generando video para prompt: A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "[2025-07-25 16:05:18,612] INFO: Guardando video en /workspace/inference_optimization/output/output_licuadora_832_480_v2_8.mp4\n",
      "  4%|▍         | 2/50 [00:06<02:41,  3.36s/it][2025-07-25 16:05:19,100] INFO: [9/10] Generando video para prompt: A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      " 94%|█████████▍| 47/50 [02:39<00:10,  3.39s/it][2025-07-25 16:08:03,504] INFO: Guardando video en /workspace/inference_optimization/output/output_licuadora_832_480_v1_9.mp4\n",
      "[2025-07-25 16:08:04,015] INFO: [10/10] Generando video para prompt: A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "  4%|▍         | 2/50 [00:06<02:41,  3.36s/it][2025-07-25 16:08:14,639] INFO: Guardando video en /workspace/inference_optimization/output/output_licuadora_832_480_v2_9.mp4\n",
      "[2025-07-25 16:08:15,150] INFO: [10/10] Generando video para prompt: A wide modern kitchen environment featuring a black Oster blender filled with fruits and ice on a white marble counter. Extend the current countertop seamlessly to the left and right, adding clean kitchen utensils, fresh fruit bowls, and a cutting board. Behind the blender, a tiled backsplash and white cabinets continue across the scene. Include soft natural lighting and subtle reflections on the countertop for a realistic look. Maintain the color tones and material style of the original image.\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]\n",
      " 94%|█████████▍| 47/50 [02:39<00:10,  3.38s/it][2025-07-25 16:10:58,690] INFO: Guardando video en /workspace/inference_optimization/output/output_licuadora_832_480_v1_10.mp4\n",
      "[2025-07-25 16:10:59,160] INFO: ✅ Todas las tareas fueron completadas.\n",
      "[rank0]:[W725 16:10:59.924393813 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "100%|██████████| 50/50 [02:49<00:00,  3.39s/it]\n",
      "\n",
      "[2025-07-25 16:11:10,650] INFO: Guardando video en /workspace/inference_optimization/output/output_licuadora_832_480_v2_10.mp4\n",
      "[2025-07-25 16:11:11,166] INFO: ✅ Todas las tareas fueron completadas.\n",
      "[rank0]:[W725 16:11:11.931528632 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
      "✅ Procesos finalizados.\n",
      "📄 Log proceso 1: /workspace/inference_optimization/output/logs/generate_vace_1_gpus_0_3.txt\n",
      "📄 Log proceso 2: /workspace/inference_optimization/output/logs/generate_vace_1_gpus_4_7.txt\n",
      "📄 Tiempo total: /workspace/inference_optimization/output/logs/tiempo_total.txt\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIGURACIÓN DE DIRECTORIOS ===\n",
    "output_dir = Path(\"/workspace/inference_optimization/output\")\n",
    "log_dir = output_dir / \"logs\"\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === RUTAS DE LOG ===\n",
    "log1_path = log_dir / \"generate_vace_1_gpus_0_3.txt\"\n",
    "log2_path = log_dir / \"generate_vace_1_gpus_4_7.txt\"\n",
    "time_log_path = log_dir / \"tiempo_total.txt\"\n",
    "\n",
    "# === TIEMPO DE INICIO GENERAL ===\n",
    "global_start = time.time()\n",
    "\n",
    "# === COMANDO 1: GPUs 0–3 ===\n",
    "start1 = time.time()\n",
    "cmd1 = f\"\"\"\n",
    "CUDA_VISIBLE_DEVICES=0,1,2,3 torchrun --nproc_per_node=4 --master_port=29501 /workspace/Wan2.1/generate_vace_1.py 2>&1 | tee {log1_path}\n",
    "\"\"\"\n",
    "proc1 = subprocess.Popen([\"bash\", \"-c\", cmd1])\n",
    "\n",
    "# === COMANDO 2: GPUs 4–7 ===\n",
    "start2 = time.time()\n",
    "cmd2 = f\"\"\"\n",
    "CUDA_VISIBLE_DEVICES=4,5,6,7 torchrun --nproc_per_node=4 --master_port=29502 /workspace/Wan2.1/generate_vace_2.py 2>&1 | tee {log2_path}\n",
    "\"\"\"\n",
    "proc2 = subprocess.Popen([\"bash\", \"-c\", cmd2])\n",
    "\n",
    "# === ESPERAR A QUE TERMINEN ===\n",
    "proc1.wait()\n",
    "end1 = time.time()\n",
    "\n",
    "proc2.wait()\n",
    "end2 = time.time()\n",
    "\n",
    "# === DURACIONES ===\n",
    "duration1 = end1 - start1\n",
    "duration2 = end2 - start2\n",
    "total_duration = time.time() - global_start\n",
    "\n",
    "# === AGREGAR TIEMPO A LOS LOGS ===\n",
    "with open(log1_path, \"a\") as f1:\n",
    "    f1.write(f\"\\n🕒 Tiempo de ejecución proceso 1 (GPUs 0–3): {duration1:.2f} segundos\\n\")\n",
    "with open(log2_path, \"a\") as f2:\n",
    "    f2.write(f\"\\n🕒 Tiempo de ejecución proceso 2 (GPUs 4–7): {duration2:.2f} segundos\\n\")\n",
    "\n",
    "# === LOG DE TIEMPO GLOBAL ===\n",
    "with open(time_log_path, \"a\") as time_log:\n",
    "    time_log.write(\n",
    "        f\"🕒 Tiempo proceso 1: {duration1:.2f} s | \"\n",
    "        f\"🕒 Tiempo proceso 2: {duration2:.2f} s | \"\n",
    "        f\"🕒 Tiempo total (ambos procesos): {total_duration:.2f} s\\n\"\n",
    "    )\n",
    "\n",
    "# === CONFIRMACIÓN FINAL ===\n",
    "print(\"✅ Procesos finalizados.\")\n",
    "print(f\"📄 Log proceso 1: {log1_path}\")\n",
    "print(f\"📄 Log proceso 2: {log2_path}\")\n",
    "print(f\"📄 Tiempo total: {time_log_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13abe261-856b-4c26-a13c-37e99f0d9565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
